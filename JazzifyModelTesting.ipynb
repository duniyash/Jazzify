{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVRaDr3PRjfn",
        "outputId": "04c68f9f-4bee-46bd-ac29-c2a0e1419aef",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install safetensors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna torch pandas scikit-learn # run if optuna is not installed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzUu3gleU2m3",
        "outputId": "5a2cce38-ef1c-4bfd-9a4b-e50f5438038c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from fractions import Fraction\n",
        "\n",
        "# Load the dataset from the CSV file (ensure output.csv is uploaded to your Colab environment)\n",
        "df = pd.read_csv('output_FullDataset.csv')\n",
        "\n",
        "# Inspect the first few rows and columns to verify column names\n",
        "print(df.head())\n",
        "print(\"Columns:\", df.columns)\n",
        "\n",
        "# Build a vocabulary mapping from note tokens to unique integers (reserve 0 for padding)\n",
        "def build_note_vocab(dataframe):\n",
        "    notes_set = set()\n",
        "    # Only use rows where 'Type' equals \"Note\"\n",
        "    for note_str in dataframe[dataframe['Type'] == \"Note\"]['Note']:\n",
        "        notes_set.update(note_str.split())\n",
        "    note2idx = {note: idx + 1 for idx, note in enumerate(sorted(notes_set))}\n",
        "    return note2idx\n",
        "\n",
        "note2idx = build_note_vocab(df)\n",
        "print(\"Note Vocabulary mapping:\", note2idx)\n",
        "\n",
        "# Build a vocabulary mapping for chord labels from the 'Active Chord' column\n",
        "def build_chord_vocab(dataframe):\n",
        "    chords = dataframe[dataframe['Type'] == \"Note\"]['Active Chord'].dropna().unique()\n",
        "    chords_str = sorted([str(chord) for chord in chords])\n",
        "    chord2idx = {chord: idx for idx, chord in enumerate(chords_str)}\n",
        "    return chord2idx\n",
        "\n",
        "chord2idx = build_chord_vocab(df)\n",
        "print(\"Chord mapping:\", chord2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSFKVn3UU4EE",
        "outputId": "49ce60a2-3bfd-42a2-f0d9-9b7eb6e9973f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    File           Part  Measure          Note  Octave  \\\n",
            "0  1974%20Blues.musicxml  MusicXML Part        1  F2.A2.C3.E-3     NaN   \n",
            "1  1974%20Blues.musicxml  MusicXML Part        1             D     3.0   \n",
            "2  1974%20Blues.musicxml  MusicXML Part        1             D     3.0   \n",
            "3  1974%20Blues.musicxml  MusicXML Part        1             E     3.0   \n",
            "4  1974%20Blues.musicxml  MusicXML Part        1             B     2.0   \n",
            "\n",
            "  Duration   Type Active Chord Chord Duration  \n",
            "0      0.0  Chord           F7            2.0  \n",
            "1      0.5   Note           F7            2.0  \n",
            "2      0.5   Note           F7            2.0  \n",
            "3      0.5   Note           F7            2.0  \n",
            "4      0.5   Note           F7            2.0  \n",
            "Columns: Index(['File', 'Part', 'Measure', 'Note', 'Octave', 'Duration', 'Type',\n",
            "       'Active Chord', 'Chord Duration'],\n",
            "      dtype='object')\n",
            "Note Vocabulary mapping: {'A': 1, 'A#': 2, 'A-': 3, 'B': 4, 'B#': 5, 'B-': 6, 'B--': 7, 'C': 8, 'C#': 9, 'C-': 10, 'D': 11, 'D#': 12, 'D-': 13, 'E': 14, 'E#': 15, 'E-': 16, 'E--': 17, 'F': 18, 'F#': 19, 'F-': 20, 'G': 21, 'G#': 22, 'G-': 23, 'G--': 24, 'G---': 25}\n",
            "Chord mapping: {'A': 0, 'A#m7': 1, 'A-': 2, 'A-+': 3, 'A-/B': 4, 'A-/B-': 5, 'A-/E-': 6, 'A-/G-': 7, 'A-13': 8, 'A-6': 9, 'A-7': 10, 'A-7 add #11': 11, 'A-7 add #9': 12, 'A-9': 13, 'A-M13': 14, 'A-M13 alter #11': 15, 'A-M9': 16, 'A-dim': 17, 'A-m': 18, 'A-m/B-': 19, 'A-m/E-': 20, 'A-m11': 21, 'A-m7': 22, 'A-m7/B-': 23, 'A-m7/D-': 24, 'A-m9': 25, 'A-maj7': 26, 'A-maj7/B-': 27, 'A-sus': 28, 'A-sus add 7': 29, 'A-sus/B- add 7': 30, 'A/E': 31, 'A13': 32, 'A6': 33, 'A7': 34, 'A7 add #11': 35, 'A7 add #9': 36, 'A7 add b9': 37, 'A9': 38, 'A9 add #11': 39, 'AM13': 40, 'AM9': 41, 'Adim': 42, 'Am': 43, 'Am11': 44, 'Am7': 45, 'Am7 alter b5': 46, 'Am7/D': 47, 'Am7/G': 48, 'Am9': 49, 'Amaj7': 50, 'Ao7': 51, 'Asus': 52, 'B': 53, 'B add 9': 54, 'B-': 55, 'B-/A': 56, 'B-/A-': 57, 'B-/B': 58, 'B-/C': 59, 'B-/D': 60, 'B-/F': 61, 'B-13': 62, 'B-13 alter #9': 63, 'B-6': 64, 'B-7': 65, 'B-7 add #11': 66, 'B-7 add #9': 67, 'B-7/C': 68, 'B-7/D#': 69, 'B-9': 70, 'B-M9': 71, 'B-m': 72, 'B-m11': 73, 'B-m6': 74, 'B-m7': 75, 'B-m7/E-': 76, 'B-m7/F': 77, 'B-m7/G': 78, 'B-m9': 79, 'B-mM7': 80, 'B-maj7': 81, 'B-maj7/C': 82, 'B-o7': 83, 'B-sus add 7': 84, 'B-sus/C add 7': 85, 'B/D': 86, 'B/D-': 87, 'B/E': 88, 'B/E-': 89, 'B13': 90, 'B7': 91, 'B7 add #9': 92, 'B7 add b9': 93, 'B7/A': 94, 'B9': 95, 'B9 add #11': 96, 'B9/F#': 97, 'BM9': 98, 'Bdim': 99, 'Bm': 100, 'Bm/F#': 101, 'Bm11': 102, 'Bm13': 103, 'Bm6': 104, 'Bm7': 105, 'Bm7 alter b5': 106, 'Bm7/A': 107, 'Bm9': 108, 'BmM7': 109, 'Bmaj7': 110, 'Bmaj7 add #11': 111, 'Bmaj7/D#': 112, 'Bmaj7/F': 113, 'Bo7': 114, 'Bsus': 115, 'C': 116, 'C#': 117, 'C#7': 118, 'C#7 add #9': 119, 'C#dim': 120, 'C#dim/B-': 121, 'C#m': 122, 'C#m11': 123, 'C#m13': 124, 'C#m7': 125, 'C#maj7': 126, 'C#o7': 127, 'C#sus add 7': 128, 'C/A': 129, 'C/A-': 130, 'C/B-': 131, 'C/D': 132, 'C/E': 133, 'C/F#': 134, 'C/G': 135, 'C13': 136, 'C6': 137, 'C7': 138, 'C7 add #11': 139, 'C7 add #9': 140, 'C7 add b9': 141, 'C7+': 142, 'C7/E': 143, 'C7/G': 144, 'C9': 145, 'CM9': 146, 'Cdim': 147, 'Cm': 148, 'Cm/B-': 149, 'Cm11': 150, 'Cm13': 151, 'Cm6': 152, 'Cm7': 153, 'Cm7 alter b5': 154, 'Cm7/B-': 155, 'Cm9': 156, 'CmM7': 157, 'Cmaj7': 158, 'Cmaj7 add #11': 159, 'Co7': 160, 'Co7/B-': 161, 'Csus': 162, 'Csus add 7': 163, 'D': 164, 'D#': 165, 'D#7': 166, 'D#9': 167, 'D#dim': 168, 'D#m': 169, 'D#m7': 170, 'D#m7 alter b5': 171, 'D#o7': 172, 'D-': 173, 'D-/A-': 174, 'D-/E': 175, 'D-/E-': 176, 'D-/G-': 177, 'D-13': 178, 'D-7': 179, 'D-7 add #11': 180, 'D-7 add #9': 181, 'D-9': 182, 'D-M13': 183, 'D-M13 alter #11': 184, 'D-M9': 185, 'D-dim': 186, 'D-m': 187, 'D-m11': 188, 'D-m7': 189, 'D-maj7': 190, 'D-maj7/C': 191, 'D-maj7/E-': 192, 'D-maj7/F': 193, 'D-sus add 7': 194, 'D/E': 195, 'D13': 196, 'D6': 197, 'D7': 198, 'D7 add #11': 199, 'D7 add #9': 200, 'D7 add b9': 201, 'D7+': 202, 'D9': 203, 'D9 add #11': 204, 'DM13': 205, 'Ddim': 206, 'Dm': 207, 'Dm/A': 208, 'Dm/E': 209, 'Dm11': 210, 'Dm13': 211, 'Dm7': 212, 'Dm7 alter b5': 213, 'Dm9': 214, 'DmM7 add 9': 215, 'Dmaj7': 216, 'Dmaj7/E': 217, 'Do7': 218, 'Dpower': 219, 'Dsus add 7': 220, 'E': 221, 'E-': 222, 'E-/B-': 223, 'E-/D-': 224, 'E-/E': 225, 'E-13': 226, 'E-6': 227, 'E-7': 228, 'E-7 add #11': 229, 'E-7 add #9': 230, 'E-7 add #9 add #11': 231, 'E-7 alter b5': 232, 'E-9': 233, 'E-9 add #11': 234, 'E-9 add 13': 235, 'E-M13': 236, 'E-M13 alter #11': 237, 'E-M9': 238, 'E-dim': 239, 'E-m': 240, 'E-m11': 241, 'E-m6': 242, 'E-m7': 243, 'E-m7/D-': 244, 'E-m9': 245, 'E-maj7': 246, 'E-maj7/F': 247, 'E-o7': 248, 'E/A': 249, 'E/B': 250, 'E/D': 251, 'E/F': 252, 'E/F#': 253, 'E/G#': 254, 'E13': 255, 'E7': 256, 'E7 add #9': 257, 'E7 alter #5': 258, 'E7 alter b5': 259, 'E7+': 260, 'E7/F': 261, 'E9': 262, 'EM13': 263, 'EM9': 264, 'Edim': 265, 'Em': 266, 'Em11': 267, 'Em13': 268, 'Em7': 269, 'Em7 add 11': 270, 'Em7 alter b5': 271, 'Em7/D': 272, 'Em9': 273, 'Emaj7': 274, 'Emaj7/F#': 275, 'Eo7': 276, 'Esus add 7': 277, 'F': 278, 'F#': 279, 'F#/E': 280, 'F#13': 281, 'F#7': 282, 'F#7 add #9': 283, 'F#7 alter b5': 284, 'F#7/C#': 285, 'F#9': 286, 'F#dim': 287, 'F#m': 288, 'F#m/A': 289, 'F#m11': 290, 'F#m7': 291, 'F#m7 add 11': 292, 'F#m7 alter b5': 293, 'F#m9': 294, 'F#maj7': 295, 'F#o7': 296, 'F#sus': 297, 'F#sus add 7': 298, 'F/B-': 299, 'F/C': 300, 'F/E': 301, 'F/E-': 302, 'F/G': 303, 'F13': 304, 'F6': 305, 'F7': 306, 'F7 add #11': 307, 'F7 add #9': 308, 'F7/A': 309, 'F9': 310, 'F9 add #11': 311, 'Fdim': 312, 'Fm': 313, 'Fm/C': 314, 'Fm11': 315, 'Fm6': 316, 'Fm7': 317, 'Fm7 alter b5': 318, 'Fm7/E-': 319, 'Fm9': 320, 'FmM7': 321, 'FmM7 add 9': 322, 'Fmaj7': 323, 'Fmaj7/G': 324, 'Fo7': 325, 'Fpower': 326, 'Fsus add 7': 327, 'G': 328, 'G#': 329, 'G#7': 330, 'G#m7': 331, 'G#maj7': 332, 'G#o7': 333, 'G#sus': 334, 'G-': 335, 'G-13': 336, 'G-7': 337, 'G-7 add #11': 338, 'G-9': 339, 'G-M13 alter #11': 340, 'G-dim': 341, 'G-m': 342, 'G-m11': 343, 'G-m7': 344, 'G-m9': 345, 'G-maj7': 346, 'G-maj7/A-': 347, 'G-o7': 348, 'G-sus': 349, 'G/A': 350, 'G/B-': 351, 'G13': 352, 'G6': 353, 'G7': 354, 'G7 add #11': 355, 'G7 add #9': 356, 'G7 add b9': 357, 'G7 alter #5': 358, 'G7 alter b5': 359, 'G7/F': 360, 'G9': 361, 'GM13': 362, 'Gdim': 363, 'Gm': 364, 'Gm/B-': 365, 'Gm/E': 366, 'Gm/F': 367, 'Gm/G-': 368, 'Gm11': 369, 'Gm13': 370, 'Gm6': 371, 'Gm7': 372, 'Gm7 alter b5': 373, 'Gm7/B-': 374, 'Gm7/C': 375, 'Gm7/F': 376, 'Gm7/G-': 377, 'Gm9': 378, 'GmM7': 379, 'GmM7 add 9 add 11': 380, 'Gmaj7': 381, 'Gmaj7/A': 382, 'Gsus': 383}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enharmonic equivalents dictionary: here '-' is used to denote flats.\n",
        "enharmonic_equivalents = {\n",
        "    'C#': 'D-', 'D-': 'C#',\n",
        "    'D#': 'E-', 'E-': 'D#',\n",
        "    'F#': 'G-', 'G-': 'F#',\n",
        "    'G#': 'A-', 'A-': 'G#',\n",
        "    'A#': 'B-', 'B-': 'A#'\n",
        "}\n",
        "\n",
        "def augment_notes(note_str, p=0.5):\n",
        "    \"\"\"\n",
        "    With probability p, replace a note token with its enharmonic equivalent.\n",
        "    \"\"\"\n",
        "    tokens = note_str.split()\n",
        "    augmented_tokens = []\n",
        "    for token in tokens:\n",
        "        if token in enharmonic_equivalents and random.random() < p:\n",
        "            augmented_tokens.append(enharmonic_equivalents[token])\n",
        "        else:\n",
        "            augmented_tokens.append(token)\n",
        "    return \" \".join(augmented_tokens)\n",
        "\n",
        "def tokenize_notes(note_str, mapping):\n",
        "    \"\"\"\n",
        "    Convert a space-separated note string into a list of integers using the note mapping.\n",
        "    \"\"\"\n",
        "    return [mapping[note] for note in note_str.split() if note in mapping]\n",
        "\n",
        "def process_octaves(octave_input, max_seq_length):\n",
        "    \"\"\"\n",
        "    Process octave information.\n",
        "    - If the input is a string, assume it is space-separated and split it.\n",
        "    - If it's not a string (e.g., a float or int), assume it's a single value and replicate it.\n",
        "    Then pad/truncate to max_seq_length.\n",
        "    \"\"\"\n",
        "    if isinstance(octave_input, str):\n",
        "        tokens = [int(o) for o in octave_input.split()]\n",
        "    else:\n",
        "        tokens = [int(octave_input)]\n",
        "\n",
        "    # Pad or truncate the list to max_seq_length\n",
        "    if len(tokens) < max_seq_length:\n",
        "        tokens = tokens + [0] * (max_seq_length - len(tokens))\n",
        "    else:\n",
        "        tokens = tokens[:max_seq_length]\n",
        "    return tokens\n",
        "\n",
        "def process_note_durations(duration_str, max_seq_length):\n",
        "    \"\"\"\n",
        "    Convert a space-separated duration string into a list of floats and pad/truncate to max_seq_length.\n",
        "    This version handles fractional durations (e.g., \"1/3\").\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    for d in duration_str.split():\n",
        "        try:\n",
        "            tokens.append(float(d))\n",
        "        except ValueError:\n",
        "            try:\n",
        "                tokens.append(float(Fraction(d)))\n",
        "            except Exception:\n",
        "                tokens.append(0.0)\n",
        "    if len(tokens) < max_seq_length:\n",
        "        tokens = tokens + [0.0] * (max_seq_length - len(tokens))\n",
        "    else:\n",
        "        tokens = tokens[:max_seq_length]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "l-SkKHxuU5fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fractions import Fraction\n",
        "\n",
        "def convert_to_float(value):\n",
        "    \"\"\"\n",
        "    Converts a string value to float.\n",
        "    If the string is a fraction (e.g., '2/3'), it converts it appropriately.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return float(value)\n",
        "    except ValueError:\n",
        "        return float(Fraction(value))\n",
        "\n",
        "class MusicDataset(Dataset):\n",
        "    def __init__(self, dataframe, note_mapping, chord_mapping, max_seq_length=32, augment=False):\n",
        "        # Filter rows to only include those where 'Type' equals \"Note\" and chord label is not NaN\n",
        "        self.data = dataframe[(dataframe['Type'] == \"Note\") & (dataframe['Active Chord'].notna())].reset_index(drop=True)\n",
        "        self.note_mapping = note_mapping\n",
        "        self.chord_mapping = chord_mapping\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "\n",
        "        # Process the note string (with optional augmentation)\n",
        "        note_str = row['Note']\n",
        "        if self.augment:\n",
        "            note_str = augment_notes(note_str)\n",
        "        tokens = tokenize_notes(note_str, self.note_mapping)\n",
        "        if len(tokens) < self.max_seq_length:\n",
        "            tokens = tokens + [0] * (self.max_seq_length - len(tokens))\n",
        "        else:\n",
        "            tokens = tokens[:self.max_seq_length]\n",
        "\n",
        "        # Process octave and note duration sequences\n",
        "        octaves = process_octaves(row['Octave'], self.max_seq_length)\n",
        "        note_durations = process_note_durations(row['Duration'], self.max_seq_length)\n",
        "\n",
        "        # Process chord label and chord duration target\n",
        "        chord_label = self.chord_mapping[str(row['Active Chord'])]\n",
        "        chord_duration = convert_to_float(row['Chord Duration'])\n",
        "\n",
        "        # Convert all data into tensors\n",
        "        tokens_tensor = torch.tensor(tokens, dtype=torch.long)\n",
        "        octaves_tensor = torch.tensor(octaves, dtype=torch.long)\n",
        "        note_durations_tensor = torch.tensor(note_durations, dtype=torch.float)\n",
        "        chord_label_tensor = torch.tensor(chord_label, dtype=torch.long)\n",
        "        chord_duration_tensor = torch.tensor(chord_duration, dtype=torch.float)\n",
        "\n",
        "        # Return tuple: (inputs, (classification target, regression target))\n",
        "        return (tokens_tensor, octaves_tensor, note_durations_tensor), (chord_label_tensor, chord_duration_tensor)\n",
        "\n",
        "# Create the dataset and DataLoader; set augment=True to enable augmentation.\n",
        "dataset = MusicDataset(df, note2idx, chord2idx, max_seq_length=32, augment=True)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Test by retrieving one batch\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    tokens, octaves, note_durations = inputs\n",
        "    chord_labels, chord_durations = targets\n",
        "    print(\"Tokens shape:\", tokens.shape)\n",
        "    print(\"Octaves shape:\", octaves.shape)\n",
        "    print(\"Note durations shape:\", note_durations.shape)\n",
        "    print(\"Chord labels shape:\", chord_labels.shape)\n",
        "    print(\"Chord durations shape:\", chord_durations.shape)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdAbwKpYU7Zy",
        "outputId": "1b181f8e-a24c-48b1-9da2-1d1b7e33a3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens shape: torch.Size([32, 32])\n",
            "Octaves shape: torch.Size([32, 32])\n",
            "Note durations shape: torch.Size([32, 32])\n",
            "Chord labels shape: torch.Size([32])\n",
            "Chord durations shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ChordPredictor(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, hidden_dim, num_layers, num_classes, max_seq_length, num_octaves=10):\n",
        "        super(ChordPredictor, self).__init__()\n",
        "\n",
        "        # Embeddings\n",
        "        self.note_embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.octave_embed = nn.Embedding(num_octaves, embed_dim)\n",
        "        self.duration_linear = nn.Linear(1, embed_dim)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.pos_embedding = nn.Parameter(torch.zeros(1, max_seq_length, embed_dim))\n",
        "\n",
        "        # Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Post-transformer processing\n",
        "        self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
        "\n",
        "        # Output heads\n",
        "        self.fc_class = nn.Linear(hidden_dim // 2, num_classes)      # Chord classification\n",
        "        self.fc_duration = nn.Linear(hidden_dim // 2, 1)             # Chord duration regression\n",
        "\n",
        "    def forward(self, tokens, octaves, note_durations):\n",
        "        token_emb = self.note_embed(tokens)                               # [B, L, D]\n",
        "        octave_emb = self.octave_embed(octaves)                           # [B, L, D]\n",
        "        duration_emb = self.duration_linear(note_durations.unsqueeze(-1)) # [B, L, D]\n",
        "\n",
        "        x = token_emb + octave_emb + duration_emb + self.pos_embedding    # [B, L, D]\n",
        "        x = x.permute(1, 0, 2)  # Transformer expects [L, B, D]\n",
        "\n",
        "        x = self.transformer_encoder(x)\n",
        "        pooled = x[0]  # Use first token's representation [B, D]\n",
        "\n",
        "        x = self.fc1(pooled)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        chord_logits = self.fc_class(x)\n",
        "        chord_duration = self.fc_duration(x).squeeze(-1)\n",
        "\n",
        "        return chord_logits, chord_duration\n"
      ],
      "metadata": {
        "id": "XWLOaqL8VzkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file as load_safetensors\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# ----- Recreate the Model -----\n",
        "model_pred = ChordPredictor(\n",
        "    vocab_size=len(note2idx) + 1,  # +1 for padding\n",
        "    embed_dim=32,\n",
        "    num_heads=4,\n",
        "    hidden_dim=256,\n",
        "    num_layers=4,\n",
        "    num_classes=len(chord2idx),\n",
        "    max_seq_length=32,\n",
        "    num_octaves=10\n",
        ")\n",
        "\n",
        "# ----- Load weights from .safetensors -----\n",
        "safetensors_path = \"chord_predictor.safetensors\"  # Replace with your actual path\n",
        "state_dict = load_safetensors(safetensors_path)\n",
        "model_pred.load_state_dict(state_dict)\n",
        "model_pred.eval()\n",
        "\n",
        "# ----- Prepare Dataset & Dataloader -----\n",
        "test_dataset = MusicDataset(df, note2idx, chord2idx, max_seq_length=32, augment=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# ----- Evaluation -----\n",
        "all_true_labels = []\n",
        "all_pred_labels = []\n",
        "all_true_durations = []\n",
        "all_pred_durations = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, targets = batch\n",
        "        tokens, octaves, durations = inputs\n",
        "        chord_labels, chord_durations = targets\n",
        "\n",
        "        chord_logits, predicted_durations = model_pred(tokens, octaves, durations)\n",
        "\n",
        "        # Get predicted chord labels (classification)\n",
        "        pred_labels = torch.argmax(chord_logits, dim=1)\n",
        "\n",
        "        # Collect all values for evaluation\n",
        "        all_true_labels.extend(chord_labels.tolist())\n",
        "        all_pred_labels.extend(pred_labels.tolist())\n",
        "        all_true_durations.extend(chord_durations.tolist())\n",
        "        all_pred_durations.extend(predicted_durations.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unnxB4lyTsuy",
        "outputId": "46929ec7-42d5-42c1-8316-b3f8fe32a878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chord Similarity\n",
        "def parse_chord(chord_str):\n",
        "    root = chord_str[:2] if len(chord_str) > 1 and chord_str[1] in ['#', '-'] else chord_str[0]\n",
        "    if \"maj\" in chord_str or \"M\" in chord_str:\n",
        "        quality = \"maj\"\n",
        "    elif \"m\" in chord_str or \"-\" in chord_str:\n",
        "        quality = \"min\"\n",
        "    elif \"dim\" in chord_str or \"o\" in chord_str:\n",
        "        quality = \"dim\"\n",
        "    elif \"7\" in chord_str or \"9\" in chord_str:\n",
        "        quality = \"dom\"\n",
        "    else:\n",
        "        quality = \"other\"\n",
        "    return root, quality\n",
        "\n",
        "def compute_chord_similarity(true_labels, pred_labels, idx2chord):\n",
        "    matches = 0\n",
        "    for t, p in zip(true_labels, pred_labels):\n",
        "        chord_t = idx2chord.get(t, \"\")\n",
        "        chord_p = idx2chord.get(p, \"\")\n",
        "        root_t, qual_t = parse_chord(chord_t)\n",
        "        root_p, qual_p = parse_chord(chord_p)\n",
        "        if root_t == root_p or qual_t == qual_p:\n",
        "            matches += 1\n",
        "    return matches / len(true_labels)\n",
        "\n",
        "# Invert chord2idx\n",
        "idx2chord = {v: k for k, v in chord2idx.items()}\n",
        "chord_similarity_score = compute_chord_similarity(all_true_labels, all_pred_labels, idx2chord)\n",
        "print(f\"Harmonic Similarity Score: {chord_similarity_score:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiuYdklGFWHP",
        "outputId": "2a67032b-3df0-4234-d0f1-cc4457dd7335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harmonic Similarity Score: 54.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_top_k_accuracies(chord_logits, true_labels, ks=[2, 5, 10, 15]):\n",
        "    \"\"\"\n",
        "    Computes Top-K accuracies for multiple values of K.\n",
        "    Returns a dictionary of {k: accuracy}.\n",
        "    \"\"\"\n",
        "    topk_results = {}\n",
        "    topk_preds = torch.topk(chord_logits, k=max(ks), dim=1).indices\n",
        "\n",
        "    for k in ks:\n",
        "        correct = sum([\n",
        "            true in pred[:k] for true, pred in zip(true_labels, topk_preds.tolist())\n",
        "        ])\n",
        "        topk_results[k] = correct / len(true_labels)\n",
        "\n",
        "    return topk_results\n"
      ],
      "metadata": {
        "id": "cCtOLsSBIgZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure these are defined:\n",
        "# chord_logits_all: Tensor of shape [N, num_classes]\n",
        "# all_true_labels: List or Tensor of true class indices\n",
        "\n",
        "topk_scores = compute_top_k_accuracies(chord_logits_all, all_true_labels, ks=[2, 5, 7, 10, 15 ,25])\n",
        "\n",
        "# Print the results\n",
        "for k, acc in topk_scores.items():\n",
        "    print(f\"Top-{k} Accuracy: {acc:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzNR785yIsTO",
        "outputId": "778c5bb6-0867-4404-f208-fc51f9ae51af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-2 Accuracy: 19.78%\n",
            "Top-5 Accuracy: 36.98%\n",
            "Top-7 Accuracy: 45.55%\n",
            "Top-10 Accuracy: 55.10%\n",
            "Top-15 Accuracy: 65.73%\n",
            "Top-25 Accuracy: 79.08%\n"
          ]
        }
      ]
    }
  ]
}